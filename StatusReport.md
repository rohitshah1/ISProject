When the project first started we wanted to work on weather and agriculture data. This status report will show the work we completed which is weeks 4-5, the goal we had in mind was to acquire, clean and even analyze crop yield and weather data for Illinois using different datasets which would allow us to have a data workflow which could be capable of generating a dataset to help with evaluating environmental drivers of crops productive levels. 
When it comes to the work which we completed we have essentially completed weeks 1-5 from the original plan we had which included data acquisition and data cleaning phases. In the first week we essentially worked on project planning which was our project proposal and research question and there we had solidified our research question with how do weather variability patterns relate to the level of corn and soybean yields overall, there are numerous things to address when it comes to delivering this answer. We then initialized our repository which was initialized on github and then we had a strict structure. We have data, scripts, workflow, docs, and our readme file. We then moved on to identify the data source with NOAA API documentation and the other one being USDA NASS Quickstats API documentation and these can be looked into at the API setup guide. Earlier, we had planned one of us would be in charge with planning, data source documentation and acquisition would be done by Rohit and the other stuff worked on by dev. In the next part we started the data acquisition where as a team we implemented full data acquisition pipelines for both data resources which i mentioned earlier. In the noaa_data the acquisition of the data source has an acquisition where we essentially automated an api call and then had some error handling with some different retry logic. We then moved to the USDA data acquisition with usda_data and this data helped us get the county level corn with Illinois records along with some trends on the data. We have artifacts in the data as well which usda_data and the usda_yields. We then had to work on API configuration system which allowed us to store and load api keys securely and then also have an interactive script to configure any credentials. These scripts helped ensure reproducible and secure api usage. We then moved onto the raw data outputs which was expected raw output files which were generated by running the acquisition scripts We then shifted to week 4-5 where we cleaned the data and this work helped us focus on designing the cleaning workflows for the NOAA weather data and USDA crop yields ,the cleaning of the NOAA helped with any uni conversion, missing values and how we handled them essentially allowing us to drop them. The daily weather observations are aggregated into county year summaries. Lastly, the USDA cleaning required the filtering of records for illinois counties and we kept corn and soybeans only, we also moved onto the data quality checks with these checks helping cleaning scripts which included the validating FIPS code, checking year coverage completeness and making sure there were no negative yields or temperatures. The outputs of this included data/processed/noaa_clean and the usda version. 
The next phase was workflow automation and this included acquiring raw data, cleaning it and looking at any errors. Then the next part was documentation where multiple documentation artifacts are completed like the api setup guide, the quick start. 
All of this allowed us to update ourtimeline and tasks status which show we completed weeks 1-5 and our next steps. 


week
tasks
status
notes
1
Project planning
done
Repository+research question done
2
Data acquisition
done
Script+logging system implemented
3
Data acquisition
done
Script+logging system implemented
4
NOAA cleaning
done
Unit conversion+aggregation
5
USDA cleaning
done
FIPS standardization and any outlier removal
6
Data integration
Next phase
Merging noaa and usda
7
Exploratory analysis 
Next phase
Regression setup
8
Modeling and visualization
Next phase
Statistical modeling
9
Report writing
Next phase
Drafting final paper



When it comes to the expected completion dates like data integration which should be done by week 6, EDA + regression modeling and then the final part will be finished by weeks 9-10. 

When it comes to the remaining tasks we want to continue with data integration which include merging the NOAA and USDA datasets using different sources and then create an integrated master dataset. Validate merged dataset for missing counties or mismatched years. But there could be some problems with this as the NOAA has inconsistent coverage across counties with missing USDA yields in some years as well playing a role in this. 

We then need to have an analysis with different EDA allowing us to look into the data, correlation analysis and different regression models to help us understand the data. Weather volatility, with yield comparisons as well. We could also implement some visualizations with the help of python to develop our scripts. 
We then move into the final delivery where we have any final report, clean data, and our final data presented. 

Contributions 
Due to sitting together and Rohit's laptop having some problems, we had dev push the code but when it came to working everyone did their part. Rohit was in charge of seeing how to plan the project and structuring the repository with different data source research. There was also a data acquisition logic, and the data acquisition scripts, cleaning, and data quality which was also looked into. Dev is in charge of data acquisition scripts, api configuration, workflow automation and the helping with pushes to git this week along with cleaning the NOAA data. 

Consequently, by the end of week 5, we are on time with everything and all the milestones are good to go. We have a good structure with scripts functioning and the workflow being reproducible. We need to continue with cleaning new data and fixing any of the potential errors which could come from this and this should allow us to move forward with the project. 
